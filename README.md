# ğŸ¤– AI2 â€“ Stochastic Grid World & MDP Controller

<p align="center">
  <img src="https://img.shields.io/badge/Language-Python-blue" />
  <img src="https://img.shields.io/badge/AI-Markov%20Decision%20Processes-purple" />
  <img src="https://img.shields.io/badge/Algorithm-Value%20Iteration-orange" />
  <img src="https://img.shields.io/badge/Environment-Stochastic%20Grid-success" />
</p>

This project is a direct continuation of the KobanGan (Assignment 1) puzzle, extending a deterministic grid environment into a stochastic setting.

An intelligent controller was implemented using **Markov Decision Processes (MDP)** and **Value Iteration**, enabling optimal decision-making under uncertainty.

---

##  Problem Description

The environment is a grid-based pressure-plate puzzle involving:
- Doors and keys
- Pressure plates affecting the environment
- Stochastic action outcomes

Unlike the deterministic version, actions may have probabilistic transitions, requiring planning under uncertainty.

---

##  AI Techniques Used

- ğŸ“Œ **Markov Decision Processes (MDP)**
- ğŸ” **Value Iteration**
- ğŸ¯ Policy extraction from value functions
- ğŸŒ« Handling stochastic transitions and rewards

---

##  Hybrid Planning Approach

To guide learning in the stochastic environment, the project integrates:

- â­ A **deterministic A\*** path (from Assignment 1)
- ğŸ§  Used as a **guiding signal / reward bias**
- ğŸ¯ Improves convergence and policy quality

This hybrid approach combines **classical planning** with **MDP-based optimization**.

---

## âš™ï¸ System Design

- Explicit state representation
- Transition probability modeling
- Reward function design
- Iterative value updates
- Action selection via learned policy

---

##  Project Structure

```bash
.
â”œâ”€â”€ ex1.py              # Deterministic agent (Assignment 1)
â”œâ”€â”€ ex2.py              # MDP-based stochastic controller
â”œâ”€â”€ pressure_plate.py   # Environment definition
â”œâ”€â”€ search.py           # Search utilities
â”œâ”€â”€ utils.py            # Helper functions
â””â”€â”€ README.md
